{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Pytorch Model into Tensorflow Model and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://github.com/aobo-y/hair-dye/blob/master/src/torch2tf.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, my environment is as follows, torch version is 0.4.1.  \n",
    "\n",
    "\n",
    "`pip install tensorflow==1.13.1 onnx==1.2.1 onnx-tf==1.1.2`\n",
    "\n",
    "\n",
    "make sure the version. some version may cause Upsample version 1 is not implemented problem.\n",
    "If that happens try to roll back to older versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:13:36.842649Z",
     "start_time": "2019-08-09T14:13:36.838018Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/root/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/ceil.py:10: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/depth_to_space.py:12: The name tf.depth_to_space is deprecated. Please use tf.compat.v1.depth_to_space instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/erf.py:9: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/__init__.py:89: UserWarning: onnx_tf.common.get_outputs_names is deprecated. It will be removed in future release. Use TensorflowGraph.get_outputs_names instead.\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/is_nan.py:9: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/log.py:10: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/upsample.py:15: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "#from onnx import version_converter, helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:13:37.482758Z",
     "start_time": "2019-08-09T14:13:37.476270Z"
    }
   },
   "outputs": [],
   "source": [
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:13:38.377808Z",
     "start_time": "2019-08-09T14:13:38.373125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(onnx.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:13:39.755329Z",
     "start_time": "2019-08-09T14:13:39.749885Z"
    }
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "DIR_PATH = os.path.abspath('') # current path\n",
    "SAVE_PATH = os.path.join(DIR_PATH, \"models/state_dicts/\")\n",
    "TORCH_MODEL_PATH = os.path.join(SAVE_PATH, \"resnet18.pt\")\n",
    "ONNX_MODEL_PATH = os.path.join(SAVE_PATH, \"resnet18.onnx\")\n",
    "TF_MODEL_PATH = os.path.join(SAVE_PATH, \"resnet18.pb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:13:40.354275Z",
     "start_time": "2019-08-09T14:13:40.349715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/DeepConcolic/models/state_dicts/resnet18.pt\n"
     ]
    }
   ],
   "source": [
    "print(TORCH_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load torch model and export it to ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:13:41.202939Z",
     "start_time": "2019-08-09T14:13:41.198427Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(path, device):\n",
    "    model = resnet18(pretrained=True)\n",
    "#     checkpoint = torch.load(path, map_location=device)\n",
    "#     model.load_state_dict(checkpoint)\n",
    "    # use appropriate device\n",
    "#     model = model.to(device)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:39:37.855157Z",
     "start_time": "2019-08-09T14:39:32.944042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run using pretrained model\n",
      "graph(%input : Float(1:3072, 3:1024, 32:32, 32:1, requires_grad=0, device=cpu),\n",
      "      %fc.weight : Float(10:512, 512:1, requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(10:1, requires_grad=1, device=cpu),\n",
      "      %200 : Float(64:27, 3:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %201 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %203 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %204 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %206 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %207 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %209 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %210 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %212 : Float(64:576, 64:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %213 : Float(64:1, requires_grad=0, device=cpu),\n",
      "      %215 : Float(128:576, 64:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %216 : Float(128:1, requires_grad=0, device=cpu),\n",
      "      %218 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %219 : Float(128:1, requires_grad=0, device=cpu),\n",
      "      %221 : Float(128:64, 64:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %222 : Float(128:1, requires_grad=0, device=cpu),\n",
      "      %224 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %225 : Float(128:1, requires_grad=0, device=cpu),\n",
      "      %227 : Float(128:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %228 : Float(128:1, requires_grad=0, device=cpu),\n",
      "      %230 : Float(256:1152, 128:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %231 : Float(256:1, requires_grad=0, device=cpu),\n",
      "      %233 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %234 : Float(256:1, requires_grad=0, device=cpu),\n",
      "      %236 : Float(256:128, 128:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %237 : Float(256:1, requires_grad=0, device=cpu),\n",
      "      %239 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %240 : Float(256:1, requires_grad=0, device=cpu),\n",
      "      %242 : Float(256:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %243 : Float(256:1, requires_grad=0, device=cpu),\n",
      "      %245 : Float(512:2304, 256:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %246 : Float(512:1, requires_grad=0, device=cpu),\n",
      "      %248 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %249 : Float(512:1, requires_grad=0, device=cpu),\n",
      "      %251 : Float(512:256, 256:1, 1:1, 1:1, requires_grad=0, device=cpu),\n",
      "      %252 : Float(512:1, requires_grad=0, device=cpu),\n",
      "      %254 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %255 : Float(512:1, requires_grad=0, device=cpu),\n",
      "      %257 : Float(512:4608, 512:9, 3:3, 3:1, requires_grad=0, device=cpu),\n",
      "      %258 : Float(512:1, requires_grad=0, device=cpu),\n",
      "      %259 : Long(1:1, requires_grad=0, device=cpu)):\n",
      "  %199 : Float(1:65536, 64:1024, 32:32, 32:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%input, %200, %201)\n",
      "  %125 : Float(1:65536, 64:1024, 32:32, 32:1, requires_grad=1, device=cpu) = onnx::Relu(%199) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %126 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%125) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:586:0\n",
      "  %202 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%126, %203, %204)\n",
      "  %129 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::Relu(%202) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %205 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%129, %206, %207)\n",
      "  %132 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::Add(%205, %126)\n",
      "  %133 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::Relu(%132) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %208 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%133, %209, %210)\n",
      "  %136 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::Relu(%208) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %211 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%136, %212, %213)\n",
      "  %139 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::Add(%211, %133)\n",
      "  %140 : Float(1:16384, 64:256, 16:16, 16:1, requires_grad=1, device=cpu) = onnx::Relu(%139) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %214 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%140, %215, %216)\n",
      "  %143 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Relu(%214) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %217 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%143, %218, %219)\n",
      "  %220 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%140, %221, %222)\n",
      "  %148 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Add(%217, %220)\n",
      "  %149 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Relu(%148) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %223 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%149, %224, %225)\n",
      "  %152 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Relu(%223) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %226 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%152, %227, %228)\n",
      "  %155 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Add(%226, %149)\n",
      "  %156 : Float(1:8192, 128:64, 8:8, 8:1, requires_grad=1, device=cpu) = onnx::Relu(%155) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %229 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%156, %230, %231)\n",
      "  %159 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Relu(%229) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %232 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%159, %233, %234)\n",
      "  %235 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%156, %236, %237)\n",
      "  %164 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Add(%232, %235)\n",
      "  %165 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Relu(%164) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %238 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%165, %239, %240)\n",
      "  %168 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Relu(%238) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %241 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%168, %242, %243)\n",
      "  %171 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Add(%241, %165)\n",
      "  %172 : Float(1:4096, 256:16, 4:4, 4:1, requires_grad=1, device=cpu) = onnx::Relu(%171) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %244 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%172, %245, %246)\n",
      "  %175 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Relu(%244) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %247 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%175, %248, %249)\n",
      "  %250 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%172, %251, %252)\n",
      "  %180 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Add(%247, %250)\n",
      "  %181 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Relu(%180) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %253 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%181, %254, %255)\n",
      "  %184 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Relu(%253) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %256 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%184, %257, %258)\n",
      "  %187 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Add(%256, %181)\n",
      "  %188 : Float(1:2048, 512:4, 2:2, 2:1, requires_grad=1, device=cpu) = onnx::Relu(%187) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1134:0\n",
      "  %189 : Float(1:512, 512:1, 1:1, 1:1, requires_grad=1, device=cpu) = onnx::GlobalAveragePool(%188) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:936:0\n",
      "  %190 : Tensor = onnx::Shape(%189)\n",
      "  %191 : Tensor = onnx::Constant[value={0}]()\n",
      "  %192 : Long(device=cpu) = onnx::Gather[axis=0](%190, %191) # /workspace/DeepConcolic/models/resnet.py:194:0\n",
      "  %194 : Tensor = onnx::Unsqueeze[axes=[0]](%192)\n",
      "  %196 : Tensor = onnx::Concat[axis=0](%194, %259)\n",
      "  %197 : Float(1:512, 512:1, requires_grad=1, device=cpu) = onnx::Reshape(%189, %196) # /workspace/DeepConcolic/models/resnet.py:194:0\n",
      "  %output : Float(1:10, 10:1, requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%197, %fc.weight, %fc.bias) # /root/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:1690:0\n",
      "  return (%output)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch_model = build_model(TORCH_MODEL_PATH, device)\n",
    "# export model to ONNX\n",
    "# ONNX need a dummy input\n",
    "dummy_input = Variable(torch.randn(1, 3, 32, 32))\n",
    "# pred = torch_model(dummy_input)\n",
    "# print(\"output size: \", pred.size())\n",
    "\n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "torch.onnx.export(torch_model, dummy_input, ONNX_MODEL_PATH, verbose=True, input_names=input_names, output_names=output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the ONNX model to tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:40:05.774144Z",
     "start_time": "2019-08-09T14:40:05.730185Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the onnx file\n",
    "onnx_model = onnx.load(ONNX_MODEL_PATH)\n",
    "# Check the model\n",
    "onnx.checker.check_model(onnx_model)\n",
    "# print('The model before conversion:\\n{}'.format(onnx_or_model))\n",
    "\n",
    "# # A full list of supported adapters can be found here:\n",
    "# # https://github.com/onnx/onnx/blob/master/onnx/version_converter.py#L21\n",
    "# # Apply the version conversion on the original model\n",
    "# onnx_model = version_converter.convert_version(onnx_or_model, 6)\n",
    "\n",
    "# print('The model after conversion:\\n{}'.format(onnx_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:40:28.879169Z",
     "start_time": "2019-08-09T14:40:12.885853Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:37: UserWarning: Unknown op ConstantFill in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of ConvInteger in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of DequantizeLinear in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of GatherND in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:37: UserWarning: Unknown op ImageScaler in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of IsInf in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of MatMulInteger in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of Mod in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of NonMaxSuppression in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of QLinearConv in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of QLinearMatMul in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of QuantizeLinear in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of Range in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of Resize in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of ReverseSequence in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of Round in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of ScatterElements in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of ScatterND in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of ThresholdedRelu in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/pool_mixin.py:272: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/reshape.py:26: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/reshape.py:31: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/gemm.py:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/pool_mixin.py:209: UserWarning: Using the pooling op in compatibility mode.This means your graph cannot be serialized.Please configure your pooling operation to only use paddings that correspond to Tensorflow SAME or VALID padding.\n",
      "  \"correspond to Tensorflow SAME or VALID padding.\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe260e1cda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe260e1cda0>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe260e1cda0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7fe260e1cda0>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "# import onnx to TF model\n",
    "tf_rep = prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:40:36.598994Z",
     "start_time": "2019-08-09T14:40:36.217519Z"
    }
   },
   "outputs": [],
   "source": [
    "tf_rep.export_graph(TF_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the model to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:52:50.224206Z",
     "start_time": "2019-08-09T14:52:50.211726Z"
    }
   },
   "outputs": [],
   "source": [
    "class ImgTransformer():\n",
    "    def __init__(self, color_aug=False):\n",
    "        self.color_aug = color_aug\n",
    "\n",
    "    def transform(self, image):\n",
    "        transformer = transforms.Compose([\n",
    "            transforms.ToTensor()        \n",
    "        ])\n",
    "\n",
    "        transform_image = transformer(image)\n",
    "\n",
    "        return transform_image\n",
    "#         return image\n",
    "\n",
    "    def load(self, path):\n",
    "        image = Image.open(path).convert('RGB')\n",
    "        return self.transform(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:52:57.738364Z",
     "start_time": "2019-08-09T14:52:57.724916Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_multi_figure(rows, dye=False):\n",
    "    fig = plt.figure()\n",
    "\n",
    "  # 3 tensors, the middle one is mask\n",
    "    if len(rows[0]) == 3:\n",
    "        names = [\"Image\", \"Mask\", \"Prediction\"]\n",
    "    else:\n",
    "        names = [\"Image\", \"Prediction\"]\n",
    "\n",
    "    for i, data in enumerate(rows):\n",
    "        img = data[0]\n",
    "        prediction = data[-1]\n",
    "\n",
    "        # reverse normalization of the oriignal image\n",
    "        img = (img + 1) / 2\n",
    "        data[0] = img\n",
    "\n",
    "        if dye:\n",
    "            transform_hue = transforms.Compose([\n",
    "            transforms.ToTensor()\n",
    "          ])\n",
    "            dyed = transform_hue(img)\n",
    "\n",
    "            dyed = prediction * dyed + (1 - prediction) * img\n",
    "            data.append(dyed)\n",
    "            names.append('Dye')\n",
    "\n",
    "\n",
    "        for j, d in enumerate(data):\n",
    "            d = d.squeeze()\n",
    "            im = d.data.numpy()\n",
    "\n",
    "            if im.shape[0] != 3:\n",
    "                im = np.expand_dims(im, axis=0)\n",
    "                im = np.concatenate((im, im, im), axis=0)\n",
    "\n",
    "            im = im.transpose(1, 2, 0)\n",
    "\n",
    "            f = fig.add_subplot(len(rows), len(data), i * len(data)+ j + 1)\n",
    "            f.imshow(im)\n",
    "            if i == 0:\n",
    "                f.set_title(names[j])\n",
    "                f.set_xticks([])\n",
    "                f.set_yticks([])\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:53:05.053864Z",
     "start_time": "2019-08-09T14:53:05.030115Z"
    }
   },
   "outputs": [],
   "source": [
    "img_path = os.path.join(DIR_PATH, \"images\", \"airplane5.png\")\n",
    "transformer = ImgTransformer(color_aug=False)\n",
    "img =  transformer.load(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:53:12.936339Z",
     "start_time": "2019-08-09T14:53:12.370607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.8352941 , 0.8352941 , 0.8392157 , ..., 0.8117647 ,\n",
       "         0.8117647 , 0.8117647 ],\n",
       "        [0.8509804 , 0.84705883, 0.8745098 , ..., 0.8235294 ,\n",
       "         0.8235294 , 0.81960785],\n",
       "        [0.8509804 , 0.85882354, 0.92941177, ..., 0.827451  ,\n",
       "         0.827451  , 0.81960785],\n",
       "        ...,\n",
       "        [0.9098039 , 0.8980392 , 0.8980392 , ..., 0.8901961 ,\n",
       "         0.8901961 , 0.8901961 ],\n",
       "        [0.9098039 , 0.8980392 , 0.9019608 , ..., 0.89411765,\n",
       "         0.8901961 , 0.8901961 ],\n",
       "        [0.90588236, 0.89411765, 0.8980392 , ..., 0.8862745 ,\n",
       "         0.8862745 , 0.8862745 ]],\n",
       "\n",
       "       [[0.92941177, 0.9137255 , 0.9137255 , ..., 0.91764706,\n",
       "         0.91764706, 0.91764706],\n",
       "        [0.94509804, 0.92156863, 0.9411765 , ..., 0.92941177,\n",
       "         0.92941177, 0.9254902 ],\n",
       "        [0.94509804, 0.93333334, 0.98039216, ..., 0.93333334,\n",
       "         0.93333334, 0.9254902 ],\n",
       "        ...,\n",
       "        [0.98039216, 0.96862745, 0.96862745, ..., 0.9647059 ,\n",
       "         0.9647059 , 0.9647059 ],\n",
       "        [0.98039216, 0.96862745, 0.96862745, ..., 0.96862745,\n",
       "         0.96862745, 0.96862745],\n",
       "        [0.96862745, 0.95686275, 0.95686275, ..., 0.95686275,\n",
       "         0.95686275, 0.95686275]],\n",
       "\n",
       "       [[0.9529412 , 0.94509804, 0.9490196 , ..., 0.9529412 ,\n",
       "         0.9529412 , 0.9490196 ],\n",
       "        [0.96862745, 0.9490196 , 0.96862745, ..., 0.96862745,\n",
       "         0.9647059 , 0.9607843 ],\n",
       "        [0.96862745, 0.9529412 , 0.99215686, ..., 0.96862745,\n",
       "         0.96862745, 0.9607843 ],\n",
       "        ...,\n",
       "        [0.99607843, 0.9843137 , 0.9843137 , ..., 0.9882353 ,\n",
       "         0.9882353 , 0.9882353 ],\n",
       "        [0.99607843, 0.9843137 , 0.9882353 , ..., 0.99215686,\n",
       "         0.99215686, 0.99215686],\n",
       "        [0.9882353 , 0.972549  , 0.9764706 , ..., 0.9843137 ,\n",
       "         0.9843137 , 0.98039216]]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(img.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:53:20.316741Z",
     "start_time": "2019-08-09T14:53:20.311364Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluateOne(img, model, absolute=True):\n",
    "    img = img.to(device).unsqueeze(0)\n",
    "    pred = model.run(img.cpu())[0]\n",
    "    pred = torch.from_numpy(pred)\n",
    "    if absolute:\n",
    "        pred[pred > .5] = 1.\n",
    "        pred[pred <= .5] = 0.\n",
    "    else:\n",
    "        pred[pred < .4] = 0\n",
    "\n",
    "    rows = [[img[0], pred[0]]]\n",
    "#     create_multi_figure(rows, dye=True)\n",
    "    print(pred[0])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-09T14:53:38.111645Z",
     "start_time": "2019-08-09T14:53:27.675104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 0., 0., 1., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "evaluateOne(img, tf_rep)\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
